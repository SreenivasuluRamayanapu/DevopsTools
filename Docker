basically to deploy an application we have 3 different environments
1. physical server
2. Virtual machine
3. container
   
our's is a SpingBoot Application   
The Application code what we have developed and along with all the dependencies required to run taht application, we can create it as 
an image(basically we are writing docker file) and push it to the Docker registry. So that we can pull the image and run it in any
environments using light weight isolated containers without any portability and compatibility issues. and then check whether API is 
opening or not.
//docker Image contain an application(.war/jar) and all the dependent Libraries required to run the application.
docker build -t ImageName:Tag .  
docker run --itd --name containerName -p 8080(dockerhost):80(container) ImageName:tag

                             As the code travels from Developer's machine to production, there are many different environments it has to
go through,to get there.each of these environments may have minor differences(osVersion etc..), docker provides a consistent environment
to the application from dev to production, easying the code deployment.

containers utilizes minimal system resources like CPU, RAM etc... from HostOS(DockerHost), so that containers are light weight.

Each application will run on a separate container and will have its own set of libraries and dependencies. This also ensures that
there is process level isolation, meaning each application is independent of other applications, giving developers assurance that they
can build applications that will not interfere with one another.

Our's is a springboot application, we are going deploy our application in to docker containers for high avaialability and zero downtime.
Docker deployment in a production environment was relatively simple and trouble-free.

Like the popular version control software Git, Docker has a social aspect in that developers and sysadmins can share their images
via Docker Hub.

Big companies like Google, VMware and Microsoft are using Docker to their Infrastructure.

Basic things to remember:
1. Create the Dockerfile,which contains all the commands to package the application(.war) with all the  dependency Libraries as an Image
   vi Dockerfile
   FROM ubuntu:16.04
   WORKDIR /tmp      // if you download any code, it goes in to working directory
   RUN apt-get update -y
   RUN apt-get install httpd -y
   RUN apt-get install wget -y
   RUN wget http://github.com/sudhansh123/javahome-app/archive/master.zip
   RUN unzip javahome-app-master.zip
   RUN mv -r javahome-app-master/* /var/www/html 
   //we are moving all the files in this 'javahome-app-master' directory to /var/www/html
   EXPOSE 80
   CMD 'service httpd start'
   ENTRYPOINT[java -jar app.jar]
   
Q. difference between CMD, RUN and ENTRYPOINT?
   both CMD and ENTRYPOINT instructions are executed at run time. i.e when container started
   In case of CMD instruction we can override it
   In case of ENTRYPOINT instruction we cant override it but we can append a command passed at run time. command is a default arguement for ENTRYPOINT
   RUN instruction will get executed before container started i.e at the time of creating image.
Q  can we use multiple command instructions at Dockerfile?
   yes, but it will pick the latest one. 
   

   
docker build -t ImageName:Tag .
docker login
docker Push ImageName:Tag
docker pull ImageNmae:Tag
docker run --itd --name containerName -p 8080(dockerhost):80(container) ImageName:tag
docker exec -it ContainerId /bin/bash
docker inspect containerId



docker-compose
It is used to run multi container applications.We can split our app in to multiple services and we can put/define all our services
in to single yaml file. so that we can start all our services with single command.
where we can specify/define different options like
build where we can specify dockerfile path to build an image and
Image where we can specify ImageName to create container and
container_name and
ports for port mapping and
environment variables and
volumes and
Networks
depends_on
links
deploy
config


For this our's is a SPRINGBOOT multi container docker application can have multiple services like
application service
webservice
database service
cache server(redis)
etc.....


Version         - version of docker-compose syntax
services        - Services are different pieces of our application i.e (app, redis, mysql).
build           - This directive can be used instead of image. specifies the location of the Dockerfile that will be used to build an image.
image           - used to specify a prebuilt image to create the container.
container_name  - used to specify the name of the container after build an image.
restart	        - tells the container to restart, if the system restarts.
environment     - this is used to pass environment variables to containers.
                  Define environment variables to be passed in to the Docker run command.
Ports           - used to map container's port to host's port. In app service, we mapped port 8080 on the host machine to port 80 in the
                  container.Maps a port from the container to the host in the following manner: host:container
expose          -                  
volumes         - Mounts a linked path on the host machine that can be used by the container
depends_on      - this ensures that mysql and redis are started before app service.so that other containers can use this container.
links           - Link this service to any other services in the Docker Compose file by specifying their names here.
networks        - 
Label           - 

vi docker-compose.yml
version: '3.3'
services:
  app:
    image: sample:1.0
    container_name: sample_app
    build: .
    ports: 
      - 80:3000
    environment:
      - MONGO_URI=mongodb://sampledb/sample
    depends_on: 
      - db
    networks: 
      - samplenet
  db:
    image: mongo:3.0.15
    container_name: sample_db
    volumes:
      - ./db:/data/db
    networks:
      samplenet:
        aliases:
          - "sampledb"
networks:
  samplenet:
    driver: bridge

Using Docker-Compose in Development






Managing the containers @large scale - docker swarm or kubernetes.
managing means like loadbalancing, autoscaling and monitoring


      

create an image from the updatedcontainer   or How to update/add a file in the Docker Image
      docker commit --m "" oldcontname  ImageName
docker logs containerId
docker system prune


Q.How to backup and restore Docker containers?
A.https://www.thegeekdiary.com/how-to-backup-and-restore-docker-containers/



Storage in Docker using volumes:
--------------------------------
Q.What are Volumes, and Why Do We Need Them?
  Volumes are external storage areas used to store data produced by a Docker container. Volumes can be located on the docker host or 
  even on remote machines.
                When a container dies all the data it has created (logs, database records, etc...) dies with it. So how do we ensure
  that data produced by containers is stored? Volumes are the answer to this question. 'Volumes are used to store the data generated
  by a container so even when its gone the data it produces still lives on'. 
  
Q.Volume Types?
here are two main types of volumes, data volumes and bind mounts. 
data volumes are used to externally store data, produced from a docker container.

creating a docker volume with dockerfile:
Data volumes can be defined in a Dockerfile using the VOLUME command
vi Dockerfile
  VOLUME /var/lib/postgresql/data
Now build an Image with dockerfile using command 'docker build -t postgre:9.6 .'
Now run the Image to create container docker using the command 'run --it --name my-postgres -e POSTGRES_PASSWORD=password -d postgres:9.6'
To view the volume, we must first find its name. To do this we must use the docker inspect command
docker inspect my-postgres
output is
[
 {
 "Destination": "/var/lib/postgresql/data",
 "Driver": "local",
 "Mode": "",
 "Name": "fd223ffe7aa7c614fc393a42e14f5b64aa38a236351f18e3c4306fe5b8a8f5af",
 "Propagation": "",
 "RW": true,
 "Source": "/var/lib/docker/volumes/fd223ffe7aa7c614fc393a42e14f5b64aa38a236351f18e3c4306fe5b8a8f5af/_data",
 "Type": "volume"
 }
]
Name attribute is the name/ID of the volume.
The Destination refers to the folder location on the container which the volume is mapped to.
Source shows the folder location on the hostmachine where the volume is mapped to.
To view the volume we created type the following command
docker volume ls | grep <volume-name>
To view the contents of the volume on the host machine, we must use the folder path defined in the  Source  attribute
ls ls /var/lib/docker/volumes/fd223ffe7aa7c614fc393a42e14f5b64aa38a236351f18e3c4306fe5b8a8f5af/_data
or

creating a docker volume with "docker run" command:
This allows us to create volumes with more meaningful names as the automatically generated name can be a bit cryptic.
Before we create our new volume, let's delete the old postgres container along with its volume 
docker rm -f -v my-postgres
create our new postgres container with a brand new and meaningful volume name (postgres-data)
docker run --name my-new-postgres -e POSTGRES_PASSWORD=password -v postgres-data:/var/lib/postgresql/data -d postgres:9.6
We have created a volume called postgres-data, using -v postgres-data:/var/lib/postgresql/data
To verify that the volume has been created type the following command 'docker volume ls | grep postgres-dat'
if we execute the docker inspect , command we will see that the Source is now using the volume name as part of the folder path to the
volume.
docker inspect my-new-postgres 
[
 {
 "Destination": "/var/lib/postgresql/data",
 "Driver": "local",
 "Mode": "z",
 "Name": "postgres-data",
 "Propagation": "",
 "RW": true,
 "Source": "/var/lib/docker/volumes/postgres-data/_data",
 "Type": "volume"
 }
    
Removing a Volume:
Volumes can be removed by executing the docker volume rm <volume-name> command. However, the container that the volume is linked to
must be stopped before the volume can be deleted. Also, keep in mind that if the volume is deleted all the data will be permanently lost.
It is recommended that a backup of the volume be performed before deletion.    
      
Q.How to Back Up Your Data Volumes to Docker Hub?


Docker Networking:
Docker takes care of the networking aspects so that the containers can communicate with other containers and also with the Docker Host.
Types of Networks
1. bridge(default) - used to connect containers on a single host(machine), you check it via ping command 
2. overlay         - it can connect the containers on a multiple machines. usually used in swarm mode
                     it is a multihost container network.
                     

1.how to create network
  docker network create --driver=bridge javahomecloud(networkname)
2.to check list of networks
  docker network ls
  networkID     networkName       driver   scope
  a09f7e6b2ac6  javahomecloud     bridge   local
  ddac4ff813b7  bridge            bridge   local
  389a7e7e8607  docker_gwbridge   bridge   local
  a09f7e6b2ac6  host              host     local
  ehw16ycy980s  ingress           overlay  swarm
  2b26c11d3469  none              null     local
  c740ydi1lm89  uber-net          overlay  swarm
         
3.attaching network while creating a container
  docker run --itd --name container1 --network javahomecloud ImageName:Tag  

4.docker network inspect networkname - Inspecting a Docker network to see more details on the network associated with Docker
                                       what are the containers sits within this network. 



Docker Swarm Cluster:
manager node - scheduling the containers across different worker nodes
worker nodes -

Q.why docker swarm  or why container orchestration?
consider a scenarion, where an application would have 5-6 microservices for a single application performing various tasks.these
microservices are put in seperate individual containers across multiple hosts, all these containers would need to talk to each other.
So you need something big like Docker Swarm (or) Kubernetes, that would load balance, scale & monitor the containers.
or
application would have a cluster of containers running across multiple hosts.containers running on multiple hosts can be manually
linked and orchestrated using Kubernetes like swarm






1.docker service create <--name --replicas --publish --network> ImageName:Tag
  --replicas flag is used to specify that this service should run on 2 different nodes
2.docker service ls
  o/p: Id  Name  Replicas Image
3.docker node ls
  o/p: Id  HostName  Status  Avaialability  ManagerStatus 
3.docker service ps serviceName
  o/p: Id  Name  Image    Node
4.docker service inspect serviceNme  
5.docker service scale serviceName=replicas   // Scaling Services (for autoscaling)
  This command will scale the vote service to 3 containers, up from 2. Because Docker Swarm uses an overlay network, it is able to
  run multiple containers of the same service on the same node.


Rolling Update:
The last thing I want to demonstrate is a rolling update of the service by making a minor change on the index.html file. Then I need to
rebuild my Docker image and push it to my public DockerHub repository.Once I've got my new image available in the remote repository,
I run the following command on the swarm manager node.
docker service update --image mengxuzhao/myapache:latest serviceName
output:
overall progress: 3 out of 3 tasks
1/3: running [==================================================>]
2/3: running [==================================================>]
3/3: running [==================================================>]
verify: Service converged



MySQL Service
docker service create --name mysqldb1 --network net1 -p 3340:3306 --mount type=volume,source=mysqldata,target=/var/lib/mysql,readonly=false --env MYSQL_ROOT_PASSWORD=root --env MYSQL_USER=root mysql:latest
Rabbit Service
docker service create --name rabbit --network net1 --env --env   rabbitmq:3-management


Q.difference between docker-compose and docker swarm?


docker system prune  // docker system prune, which will clean up containers, images, volumes, and networks all in one command
                     // To Remove unused data
WARNING! This will remove:
        - all stopped containers
        - all networks not used by at least one container
        - all dangling images
        - all build cache
Total reclaimed space: 1.84kB


docker cp
docker commit
docker logs
docker update
docker top


        

  



    
    
    
